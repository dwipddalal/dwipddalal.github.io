<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Constructive Distortion: Improving MLLMs with Attention‚ÄëGuided Image Warping</title>
  <style>
    /* ---------- LAYOUT ---------- */
    :root {
      --text: #333;
      --accent: #4A90E2;
      --bg-light: #f8f9fa;
      --shadow: 0 4px 20px rgba(0,0,0,.08);
      --rad: 12px;
    }
    * {box-sizing:border-box; margin:0; padding:0;}
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      max-width: 1200px;
      margin: 0 auto;
      padding: 60px 20px;
      line-height: 1.6;
      background:#fff;
      color: var(--text);
    }
    h1{font-size:48px;font-weight:400;text-align:center;margin-bottom:40px;line-height:1.1;letter-spacing:-.5px;}
    .authors, .affiliations, .contact, .conference{text-align:center;}
    .authors{font-size:24px;color:var(--accent);line-height:1.4;margin-bottom:20px;}
    .affiliations{font-size:18px;color:#666;margin-bottom:30px;}
    .affiliation-item{display:inline-block;margin:0 15px 8px 0;font-weight:500;}
    .contact{font-size:16px;color:#888;margin-bottom:30px;}
    .conference{font-size:20px;font-weight:500;margin-bottom:40px;}

    /* ---------- BUTTONS ---------- */
    .button-row{display:flex;justify-content:center;flex-wrap:wrap;gap:15px;margin-bottom:80px;}
    .btn{display:inline-flex;align-items:center;gap:8px;padding:12px 26px;background:#2d2d2d;color:#fff;border:none;border-radius:30px;text-decoration:none;font-size:16px;font-weight:500;transition:.2s;cursor:pointer;}
    .btn:hover{background:#1a1a1a;transform:translateY(-1px);}

    /* ---------- ANIMATION VIDEO ---------- */
    .animation-section{text-align:center;margin:60px 0 80px 0;}
    .animation-section video{width:100%;max-width:900px;display:block;margin:0 auto;background:transparent;}

    /* ---------- VIDEO GRID ---------- */
    .video-grid-section{text-align:center;margin:80px 0;}
    .video-grid-section h2{font-size:36px;font-weight:600;margin-bottom:50px;}
    .video-grid{display:grid;gap:20px;max-width:1200px;margin:0 auto;
      grid-template-columns:repeat(auto-fill,minmax(200px,1fr));}
    .video-item{background:#111;border-radius:var(--rad);overflow:hidden;box-shadow:var(--shadow);border:4px solid #ff4444;transition:.3s;aspect-ratio:1/1;display:flex;align-items:center;justify-content:center;}
    .video-item.video-ended{border-color:#4CAF50;}
    .video-item:hover{transform:translateY(-5px);}
    .video-item video{width:100%;height:100%;object-fit:contain;display:block;background:#111;}

    /* ---------- ABSTRACT ---------- */
    .abstract{background:var(--bg-light);padding:50px;border-radius:var(--rad);border-left:4px solid var(--accent);margin:80px 0;}
    .abstract h2{font-size:28px;font-weight:600;margin-bottom:30px;}
    .abstract p{font-size:18px;line-height:1.7;}

    /* ---------- QUERY EXAMPLES CAROUSEL ---------- */
    .carousel-container{position:relative;max-width:800px;margin:0 auto;overflow:hidden;border-radius:var(--rad);}
    .carousel-wrapper{display:flex;transition:transform 0.5s ease-in-out;}
    .query-example{background:#fff;border-radius:var(--rad);overflow:hidden;box-shadow:var(--shadow);display:flex;flex-direction:column;transition:.3s;min-width:300px;margin:0 15px;}
    .query-example:hover{transform:translateY(-3px);}
    .query-text{padding:25px;background:linear-gradient(135deg,#f8f9fa 0%,#e9ecef 100%);}
    .query-text h3{font-size:16px;font-weight:600;margin-bottom:10px;}
    .example-query{background:#e3f2fd;padding:15px;border-radius:6px;border-left:3px solid var(--accent);font-style:italic;font-size:14px;}
    .query-video video{width:100%;display:block;aspect-ratio:1/1;object-fit:contain;}
    .video-caption{padding:20px;font-size:14px;color:#666;background:#fff;}

    /* Carousel Navigation */
    .carousel-nav{position:absolute;top:50%;transform:translateY(-50%);background:rgba(255,255,255,0.9);border:none;border-radius:50%;width:40px;height:40px;cursor:pointer;font-size:18px;color:#333;box-shadow:var(--shadow);transition:.2s;z-index:10;}
    .carousel-nav:hover{background:#fff;transform:translateY(-50%) scale(1.1);}
    .carousel-nav.prev{left:10px;}
    .carousel-nav.next{right:10px;}
    .carousel-dots{display:flex;justify-content:center;margin-top:20px;}
    .carousel-dot{width:10px;height:10px;border-radius:50%;background:#ddd;margin:0 5px;cursor:pointer;transition:.2s;}
    .carousel-dot.active{background:var(--accent);}

    /* ---------- RESPONSIVE ---------- */
    @media(max-width:768px){
      h1{font-size:36px;}
      .authors{font-size:20px;}
      .button-row{flex-direction:column;align-items:center;}
      .btn{width:250px;justify-content:center;}
      .abstract{padding:30px;}

      /* Carousel responsive */
      .carousel-container{max-width:100%;padding:0 20px;}
      .query-example{min-width:280px;margin:0 10px;}
      .carousel-nav{width:35px;height:35px;font-size:16px;}
      .carousel-nav.prev{left:5px;}
      .carousel-nav.next{right:5px;}
    }

    @media(max-width:480px){
      .query-example{min-width:260px;}
      .carousel-container{padding:0 10px;}
    }

    /* ---------- RESULTS TABLE ---------- */
    .results-table-section{margin:80px 0;}
    .results-table-section h2{font-size:36px;font-weight:600;margin-bottom:20px;text-align:center;}
    .results-table-section .table-caption{font-size:16px;color:#666;margin-bottom:30px;text-align:center;max-width:900px;margin-left:auto;margin-right:auto;}
    .results-table{width:100%;border-collapse:collapse;font-size:14px;margin:0 auto;background:#fff;box-shadow:var(--shadow);border-radius:var(--rad);overflow:hidden;}
    .results-table th,.results-table td{padding:10px 12px;text-align:center;border-bottom:1px solid #e0e0e0;}
    .results-table th{background:#2d2d2d;color:#fff;font-weight:600;}
    .results-table .section-header{background:#f5f5f5;font-weight:600;}
    .results-table .section-header td{text-align:left;padding-left:20px;font-size:15px;}
    .results-table .highlight{background:#e8f4e8;}
    .results-table .best td{font-weight:700;}
    .results-table .delta{background:#f9f9f9;font-style:italic;color:#666;}
    .results-table a{color:var(--accent);text-decoration:none;}
    .results-table a:hover{text-decoration:underline;}
    @media(max-width:768px){
      .results-table{font-size:12px;}
      .results-table th,.results-table td{padding:8px 6px;}
      .results-table-section{overflow-x:auto;}
    }

    /* ---------- VISUAL COMPARISONS ---------- */
    .visual-comparison-section{margin:80px 0;}
    .visual-comparison-section h2{font-size:36px;font-weight:600;margin-bottom:20px;text-align:center;}
    .visual-comparison-section .section-desc{font-size:18px;color:#666;margin-bottom:40px;text-align:center;max-width:900px;margin-left:auto;margin-right:auto;line-height:1.6;}
    .comparison-block{margin-bottom:60px;}
    .comparison-block h3{font-size:24px;font-weight:600;margin-bottom:15px;text-align:center;color:#2d2d2d;}
    .comparison-block .block-caption{font-size:16px;color:#666;margin-bottom:25px;text-align:center;max-width:800px;margin-left:auto;margin-right:auto;}
    .comparison-image-wrapper{background:#fff;border-radius:var(--rad);box-shadow:var(--shadow);overflow:hidden;padding:20px;}
    .comparison-image-wrapper img{width:100%;height:auto;display:block;border-radius:8px;}
    @media(max-width:768px){
      .visual-comparison-section h2{font-size:28px;}
      .comparison-block h3{font-size:20px;}
      .comparison-image-wrapper{padding:12px;}
    }
  </style>
</head>
<body>
  <h1>Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping</h1>
  <div class="authors">
    <a href="https://dwipddalal.github.io/">Dwip Dalal</a>¬π, Gautam Vashishtha¬≤, Utkarsh Mishra¬≥, <a href="https://wjdghks950.github.io/">Jeonghwan Kim</a>¬π, <br>
    <a href="https://madhav-kanda.github.io/">Madhav Kanda</a>¬π, <a href="https://hyeonjeongha.github.io/">Hyeonjeong Ha</a>¬π, <a href="https://slazebni.cs.illinois.edu/">Svetlana Lazebnik</a>¬π, <a href="https://blender.cs.illinois.edu/hengji.html">Heng Ji</a>¬π, <a href="https://unnat.github.io/">Unnat Jain</a>‚Å¥
  </div>
  <div class="affiliations">
    ¬πUniversity¬†of¬†Illinois¬†Urbana‚ÄìChampaign&nbsp;&nbsp;¬≤Skan¬†AI&nbsp;&nbsp;¬≥Texas‚ÄØA&M¬†University&nbsp;&nbsp;‚Å¥University¬†of¬†California,¬†Irvine
  </div>
  <!-- <div class="contact">Correspondence¬†to:‚ÄØdwip2@illinois.edu</div>
  <div class="conference">Under¬†Review</div> -->

  <!-- ---------- ACTION BUTTONS ---------- -->
  <div class="button-row">
    <a class="btn" href="#presentation">üìñ Presentation</a>
    <a class="btn" href="https://arxiv.org/pdf/2510.09741">üìÑ Paper</a>
    <a class="btn" href="https://github.com/dwipddalal/Attwarp">üíª Code</a>
    <a class="btn" href="#visual-comparisons">üìä Results</a>
    <!-- CHANGED: turn BibTeX into a modal-triggering button -->
    <button id="open-bibtex" class="btn" type="button" aria-haspopup="dialog" aria-controls="bibtex-modal">üìö BibTeX</button>
  </div>

  <!-- ---------- ANIMATION VIDEO ---------- -->
  <section class="animation-section" id="presentation">
    <video autoplay muted playsinline>
      <source src="Attwarp_Vid1_cropped.mp4" type="video/mp4">
    </video>
  </section>

  <!-- ---------- VIDEO GALLERY ---------- -->
  <section class="video-grid-section" id="videos">
    <h2>üé¨ Video Gallery</h2>
    <div class="video-grid">
      <!-- All videos inside videos_fixed (auto-generated list) -->
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/1526520f65bff202_78/output_runs/run_1/1526520f65bff202_78_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201462454_n508641/output_runs/run_0/201462454_n508641_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/20667979_n181355/output_runs/run_0/20667979_n181355_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201935992_n500209/output_runs/run_0/201935992_n500209_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201885221_n222297/output_runs/run_0/201885221_n222297_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201957086_n536256/output_runs/run_1/201957086_n536256_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201623664_n501609/output_runs/run_0/warp_anim2.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201492498_n9856/output_runs/run_0/warp_anim2.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201864508_n481655/output_runs/run_0/201864508_n481655_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201713529_n455563/output_runs/run_0/warp_anim2.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/201952896_n525029/output_runs/run_0/201952896_n525029_warp_anim.mp4" type="video/mp4"></source></video></div>
      <div class="video-item"><video autoplay muted playsinline preload="auto"><source src="videos_fixed/warp_anim4.mp4" type="video/mp4"></source></video></div>
    </div>
  </section>

  <!-- ---------- ABSTRACT ---------- -->
  <section class="abstract">
    <h2>üìù TLDR</h2>
    <p>
      MLLMs often miss small details and spatial relations in cluttered scenes, leading to errors in fine-grained perceptual grounding. We introduce AttWarp, a lightweight method that allocates more resolution to query-relevant content while compressing less informative areas, all while preserving global context. At test time, the approach uses an MLLM's cross-modal attention to perform rectilinear warping of the input image, reallocating spatial resolution toward regions the model deems important, without changing model weights or architecture. This attention-guided warping preserves all original image information but redistributes it non-uniformly, so small objects and subtle relationships become easier for the same model to read while the global layout remains intact. AttWarp consistently improves accuracy, strengthens compositional reasoning, and reduces hallucinations.
  </section>

  <!-- ---------- VISUAL COMPARISONS ---------- -->
  <section class="visual-comparison-section" id="visual-comparisons">
    <h2>üîç Visual Comparisons</h2>
    <p class="section-desc">Qualitative examples demonstrating how AttWarp improves visual grounding compared to baseline MLLMs and other visual prompting methods.</p>
    
    <!-- Comparison with Baselines -->
    <div class="comparison-block">
      <h3>Comparison with Other Methods</h3>
      <p class="block-caption">AttWarp (Warping) achieves superior spatial grounding compared to FGVP (Green Masking), SoM (Visual Grounding), API (Alpha Blending), and ViCrop (Cropping). Our method preserves global context while reallocating resolution to query-relevant regions.</p>
      <div class="comparison-image-wrapper">
        <img src="comparison_baseline_display.png" alt="Comparison of AttWarp with baseline methods including FGVP, SoM, API, and ViCrop">
      </div>
    </div>

    <!-- AttWarp vs Base MLLM -->
    <div class="comparison-block">
      <h3>AttWarp vs Base MLLM</h3>
      <p class="block-caption">Examples showing how attention-guided warping helps MLLMs correctly answer visual questions. The warped grid visualization shows how AttWarp redistributes spatial resolution toward query-relevant regions, enabling accurate answers where base models fail.</p>
      <div class="comparison-image-wrapper">
        <img src="results.png" alt="Examples of AttWarp improving MLLM responses compared to base models">
      </div>
    </div>
  </section>

  <!-- ---------- QUERY‚ÄëAWARE EXAMPLES ---------- -->
  <section class="results-gallery">
    <h2 style="text-align:center;font-size:36px;font-weight:600;margin-bottom:50px;">üéØ How Query‚ÄëAware Warping Works</h2>
    <p style="text-align:center;font-size:18px;color:#666;margin-bottom:50px;">Each example shows how our method adaptively warps images based on the query, highlighting relevant regions while preserving spatial relationships.</p>
    <div class="carousel-container">
      <div class="carousel-wrapper" id="carousel-wrapper">
      <!-- Example #1 -->
      <div class="query-example">
        <div class="query-text"><h3>Query:</h3>
          <div class="example-query">"What is the alcohol content?"</div>
        </div>
        <div class="query-video"><video controls preload="metadata"><source src="videos_fixed/1526520f65bff202_78/output_runs/run_1/1526520f65bff202_78_warp_anim.mp4" type="video/mp4"></video></div>
        <div class="video-caption">The warped view enlarges the ABV text region on the can.</div>
      </div>
      <!-- Example #2 -->
      <div class="query-example">
        <div class="query-text"><h3>Query:</h3>
          <div class="example-query">"Does the bat look white?"</div>
        </div>
        <div class="query-video"><video controls preload="metadata"><source src="videos_fixed/201462454_n508641/output_runs/run_0/201462454_n508641_warp_anim.mp4" type="video/mp4"></video></div>
        <div class="video-caption">Warping focuses on the bat region to reveal its true color.</div>
      </div>
      <!-- Example #3 -->
      <div class="query-example">
        <div class="query-text"><h3>Query:</h3>
          <div class="example-query">"Is the hat made of cloth?"</div>
        </div>
        <div class="query-video"><video controls preload="metadata"><source src="videos_fixed/201492498_n9856/output_runs/run_0/warp_anim2.mp4" type="video/mp4"></video></div>
        <div class="video-caption">The warped animation magnifies the hat texture for better material recognition.</div>
      </div>
      <!-- Example #4 -->
      <div class="query-example">
        <div class="query-text"><h3>Query:</h3>
          <div class="example-query">"Which color is the belt?"</div>
        </div>
        <div class="query-video"><video controls preload="metadata"><source src="videos_fixed/201739131_n485969/output_runs/run_0/201739131_n485969_warp_anim.mp4" type="video/mp4"></video></div>
        <div class="video-caption">Our method highlights the belt area to disambiguate its color.</div>
      </div>
      </div>

      <!-- Carousel Navigation -->
      <button class="carousel-nav prev" id="prev-btn">‚Äπ</button>
      <button class="carousel-nav next" id="next-btn">‚Ä∫</button>

      <!-- Carousel Dots -->
      <div class="carousel-dots" id="carousel-dots">
        <div class="carousel-dot active" data-slide="0"></div>
        <div class="carousel-dot" data-slide="1"></div>
        <div class="carousel-dot" data-slide="2"></div>
        <div class="carousel-dot" data-slide="3"></div>
      </div>
    </div>
  </section>

  <!-- ---------- RESULTS TABLE ---------- -->
  <section class="results-table-section" id="quantitative-results">
    <h2>üìä Quantitative Results</h2>
    <p class="table-caption"><strong>Table 1:</strong> Main results on TextVQA, GQA, MMMU, POPE, and DocVQA datasets in accuracy (%).</p>
    <table class="results-table">
      <thead>
        <tr>
          <th>#</th>
          <th>Methods</th>
          <th>Key Technique</th>
          <th>TextVQA</th>
          <th>GQA</th>
          <th>MMMU</th>
          <th>POPE</th>
          <th>DocVQA</th>
        </tr>
      </thead>
      <tbody>
        <!-- LLaVA Section -->
        <tr class="section-header">
          <td colspan="8"><strong>LLaVA</strong> <em>(MLP vision-language connector & open data)</em></td>
        </tr>
        <tr>
          <td>1</td>
          <td>Base MLLM</td>
          <td></td>
          <td>49.3</td>
          <td>60.5</td>
          <td>36.9</td>
          <td>85.3</td>
          <td>18.1</td>
        </tr>
        <tr>
          <td>2</td>
          <td>FGVP-mask</td>
          <td>Green mask overlay</td>
          <td>39.4</td>
          <td>59.2</td>
          <td>36.1</td>
          <td>85.3</td>
          <td>19.0</td>
        </tr>
        <tr>
          <td>3</td>
          <td>FGVP-blur</td>
          <td>Blur background</td>
          <td>33.9</td>
          <td>59.5</td>
          <td>35.0</td>
          <td>83.1</td>
          <td>18.6</td>
        </tr>
        <tr>
          <td>4</td>
          <td>SoM</td>
          <td>Grounded segments</td>
          <td>18.8</td>
          <td>54.5</td>
          <td>35.6</td>
          <td>78.5</td>
          <td>15.8</td>
        </tr>
        <tr>
          <td>5</td>
          <td>API</td>
          <td>Alpha channel fade</td>
          <td>49.9</td>
          <td>60.6</td>
          <td>36.9</td>
          <td>85.9</td>
          <td>17.4</td>
        </tr>
        <tr>
          <td>6</td>
          <td>ViCrop</td>
          <td>Add object crop</td>
          <td><u>56.3</u></td>
          <td><u>60.9</u></td>
          <td><u>37.2</u></td>
          <td><u>87.0</u></td>
          <td><u>22.5</u></td>
        </tr>
        <tr class="highlight">
          <td>7</td>
          <td>AttWarp</td>
          <td>Rectilinear warping</td>
          <td>58.1</td>
          <td>63.7</td>
          <td>40.4</td>
          <td>87.5</td>
          <td>25.5</td>
        </tr>
        <tr class="highlight">
          <td>8</td>
          <td>AttWarp-Distill</td>
          <td>Efficient inference</td>
          <td>57.2</td>
          <td>62.7</td>
          <td>38.8</td>
          <td>87.4</td>
          <td>22.4</td>
        </tr>
        <tr class="highlight best">
          <td>9</td>
          <td>AttWarp-Chain</td>
          <td>Adaptive Chains</td>
          <td><strong>60.3</strong></td>
          <td><strong>64.4</strong></td>
          <td><strong>41.6</strong></td>
          <td><strong>88.2</strong></td>
          <td><strong>27.6</strong></td>
        </tr>
        <!-- Qwen Section -->
        <tr class="section-header">
          <td colspan="8"><strong>Qwen</strong> <em>(Cross-attention VL adapter & partially closed data)</em></td>
        </tr>
        <tr>
          <td>11</td>
          <td>Base MLLM</td>
          <td></td>
          <td>81.0</td>
          <td><u>62.4</u></td>
          <td>47.3</td>
          <td>86.1</td>
          <td>77.3</td>
        </tr>
        <tr>
          <td>12</td>
          <td>FGVP-mask</td>
          <td>Green mask overlay</td>
          <td>77.3</td>
          <td>55.8</td>
          <td>46.0</td>
          <td>84.4</td>
          <td>56.6</td>
        </tr>
        <tr>
          <td>13</td>
          <td>FGVP-blur</td>
          <td>Blur background</td>
          <td>72.3</td>
          <td>55.8</td>
          <td>46.5</td>
          <td>81.3</td>
          <td>38.6</td>
        </tr>
        <tr>
          <td>14</td>
          <td>SoM</td>
          <td>Grounded segments</td>
          <td>61.5</td>
          <td>47.8</td>
          <td>45.1</td>
          <td>75.8</td>
          <td>57.4</td>
        </tr>
        <tr>
          <td>15</td>
          <td>API</td>
          <td>Alpha channel fade</td>
          <td>81.6</td>
          <td>61.1</td>
          <td><u>47.4</u></td>
          <td>85.8</td>
          <td>68.4</td>
        </tr>
        <tr>
          <td>16</td>
          <td>ViCrop</td>
          <td>Add object crop</td>
          <td><u>83.8</u></td>
          <td>60.6</td>
          <td>47.1</td>
          <td><u>86.7</u></td>
          <td><u>82.5</u></td>
        </tr>
        <tr class="highlight">
          <td>17</td>
          <td>AttWarp</td>
          <td>Rectilinear warping</td>
          <td>84.7</td>
          <td>64.0</td>
          <td>50.4</td>
          <td>87.4</td>
          <td>84.1</td>
        </tr>
        <tr class="highlight">
          <td>18</td>
          <td>AttWarp-Distill</td>
          <td>Efficient inference</td>
          <td>84.1</td>
          <td>63.1</td>
          <td>48.9</td>
          <td>87.2</td>
          <td>81.8</td>
        </tr>
        <tr class="highlight best">
          <td>19</td>
          <td>AttWarp-Chain</td>
          <td>Adaptive Chains</td>
          <td><strong>85.9</strong></td>
          <td><strong>64.8</strong></td>
          <td><strong>51.0</strong></td>
          <td><strong>88.0</strong></td>
          <td><strong>85.3</strong></td>
        </tr>
      </tbody>
    </table>
  </section>

  <!-- ---------- BIBTEX MODAL (NEW) ---------- -->
  <div class="modal-backdrop" id="bibtex-modal" role="dialog" aria-modal="true" aria-labelledby="bibtex-title">
    <div class="modal">
      <div class="modal-header">
        <div class="modal-title" id="bibtex-title">BibTeX</div>
        <div class="modal-actions">
          <button class="icon-btn" id="copy-bib">Copy</button>
          <button class="icon-btn" id="download-bib">Download .bib</button>
          <button class="close-btn" id="close-bib" aria-label="Close">√ó</button>
        </div>
      </div>
      <div class="modal-body">
        <div class="code-wrap">
          <pre id="bibtex-code" style="white-space:pre-wrap;overflow-wrap:anywhere;word-break:break-word;max-width:100%;">@article{dalal2025constructive,
  title={Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping},
  author={Dalal, Dwip and Vashishtha, Gautam and Mishra, Utkarsh and Kim, Jeonghwan and Kanda, Madhav and Ha, Hyeonjeong and Lazebnik, Svetlana and Ji, Heng and Jain, Unnat},
  journal={arXiv preprint arXiv:2510.09741},
  year={2025}
}</pre>
        </div>
      </div>
    </div>
  </div>

  <!-- ---------- BORDER-ON-FINISH SCRIPT + BIBTEX SCRIPT ---------- -->
  <script>
    // Mark tiles green when video ends
    document.querySelectorAll('.video-item video').forEach(v=>{
      v.addEventListener('ended',()=>v.closest('.video-item').classList.add('video-ended'));
    });

    // --- BibTeX modal logic ---
    const openBtn = document.getElementById('open-bibtex');
    const modal = document.getElementById('bibtex-modal');
    const closeBtn = document.getElementById('close-bib');
    const copyBtn = document.getElementById('copy-bib');
    const dlBtn = document.getElementById('download-bib');
    const codeEl = document.getElementById('bibtex-code');

    function openModal(){
      modal.style.display = 'flex';
      // trap focus on open
      setTimeout(()=>closeBtn.focus(), 0);
      document.body.style.overflow = 'hidden';
    }
    function closeModal(){
      modal.style.display = 'none';
      document.body.style.overflow = '';
      openBtn.focus();
    }

    openBtn.addEventListener('click', openModal);
    closeBtn.addEventListener('click', closeModal);
    modal.addEventListener('click', (e)=>{ if(e.target === modal) closeModal(); });
    document.addEventListener('keydown', (e)=>{ if(e.key === 'Escape' && modal.style.display === 'flex') closeModal(); });

    copyBtn.addEventListener('click', async ()=>{
      const text = codeEl.textContent.trim();
      try{
        await navigator.clipboard.writeText(text);
        copyBtn.textContent = 'Copied!';
        setTimeout(()=>copyBtn.textContent = 'Copy', 1200);
      }catch{
        // Fallback: create a hidden textarea
        const ta = document.createElement('textarea');
        ta.value = text;
        document.body.appendChild(ta);
        ta.select();
        document.execCommand('copy');
        document.body.removeChild(ta);
        copyBtn.textContent = 'Copied!';
        setTimeout(()=>copyBtn.textContent = 'Copy', 1200);
      }
    });

    dlBtn.addEventListener('click', ()=>{
      const blob = new Blob([codeEl.textContent.trim() + '\n'], {type: 'text/x-bibtex'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'attwarp.bib';
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
    });
  </script>

  <!-- ---------- CAROUSEL SCRIPT ---------- -->
  <script>
    class Carousel {
      constructor() {
        this.wrapper = document.getElementById('carousel-wrapper');
        this.dots = document.querySelectorAll('.carousel-dot');
        this.prevBtn = document.getElementById('prev-btn');
        this.nextBtn = document.getElementById('next-btn');
        this.currentSlide = 0;
        this.totalSlides = this.dots.length;
        this.autoPlayInterval = null;

        this.init();
      }

      init() {
        this.prevBtn.addEventListener('click', () => this.prevSlide());
        this.nextBtn.addEventListener('click', () => this.nextSlide());

        this.dots.forEach((dot, index) => {
          dot.addEventListener('click', () => this.goToSlide(index));
        });

        this.startAutoPlay();
        this.updateButtons();
      }

      updateSlide() {
        this.wrapper.style.transform = `translateX(-${this.currentSlide * 330}px)`;

        this.dots.forEach((dot, index) => {
          dot.classList.toggle('active', index === this.currentSlide);
        });

        this.updateButtons();
      }

      nextSlide() {
        this.currentSlide = (this.currentSlide + 1) % this.totalSlides;
        this.updateSlide();
        this.resetAutoPlay();
      }

      prevSlide() {
        this.currentSlide = (this.currentSlide - 1 + this.totalSlides) % this.totalSlides;
        this.updateSlide();
        this.resetAutoPlay();
      }

      goToSlide(index) {
        this.currentSlide = index;
        this.updateSlide();
        this.resetAutoPlay();
      }

      updateButtons() {
        this.prevBtn.style.opacity = this.currentSlide === 0 ? '0.5' : '1';
        this.nextBtn.style.opacity = this.currentSlide === this.totalSlides - 1 ? '0.5' : '1';
      }

      startAutoPlay() {
        this.autoPlayInterval = setInterval(() => {
          this.nextSlide();
        }, 4000);
      }

      resetAutoPlay() {
        clearInterval(this.autoPlayInterval);
        this.startAutoPlay();
      }
    }

    // Initialize carousel when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      new Carousel();
    });
  </script>
</body>
</html>
